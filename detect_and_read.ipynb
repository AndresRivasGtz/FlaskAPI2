{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from local_utils import detect_lp\n",
    "from os.path import splitext\n",
    "from tensorflow.keras.models  import model_from_json\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import requests\n",
    "\n",
    "def load_model(path):\n",
    "    try:\n",
    "        path = splitext(path)[0]\n",
    "        with open('%s.json' % path, 'r') as json_file:\n",
    "            model_json = json_file.read()\n",
    "        model = model_from_json(model_json, custom_objects={})\n",
    "        model.load_weights('%s.h5' % path)\n",
    "        print(\"Model Loaded successfully...\")\n",
    "        print(\"Detecting License Plate ... \")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "def preprocess_image(image_path,resize=False):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img / 255\n",
    "    if resize:\n",
    "        img = cv2.resize(img, (224,224))\n",
    "    return img\n",
    "\n",
    "def get_plate(image_path, wpod_net, Dmax=608, Dmin = 608):\n",
    "    vehicle = preprocess_image(image_path)\n",
    "    ratio = float(max(vehicle.shape[:2])) / min(vehicle.shape[:2])\n",
    "    side = int(ratio * Dmin)\n",
    "    bound_dim = min(side, Dmax)\n",
    "    _ , LpImg, _, cor = detect_lp(wpod_net, vehicle, bound_dim, lp_threshold=0.5)\n",
    "    return vehicle, LpImg, cor\n",
    "\n",
    "\n",
    "def recognize_plate(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    gray = cv2.resize(gray, None, fx = 3, fy = 3, interpolation = cv2.INTER_CUBIC)\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    ret, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "    rect_kern = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "    dilation = cv2.dilate(thresh, rect_kern, iterations = 1)\n",
    "    cv2.imwrite('detection/placas.jpg', dilation)\n",
    "\n",
    "    try:\n",
    "        contours, hierarchy = cv2.findContours(dilation, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    except:\n",
    "        ret_img, contours, hierarchy = cv2.findContours(dilation, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    sorted_contours = sorted(contours, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "    im2 = dilation.copy()\n",
    "    \n",
    "    plate_num = 0\n",
    "    for cnt in sorted_contours:\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        height, width = im2.shape\n",
    "        if height / float(h) > 6: continue\n",
    "        ratio = h / float(w)\n",
    "        if ratio < 1.1: continue\n",
    "        area = h * w\n",
    "        if width / float(w) > 15: continue\n",
    "        if area < 100: continue\n",
    "        rect = cv2.rectangle(im2, (x,y), (x+w, y+h), (0,255,0),2)\n",
    "        roi = thresh[y-5:y+h+5, x-5:x+w+5]\n",
    "        roi = cv2.bitwise_not(roi)\n",
    "        roi = cv2.medianBlur(roi, 5)\n",
    "        cv2.imwrite(f\"letras/{plate_num}.jpg\", roi)\n",
    "        plate_num += 1\n",
    "    print(plate_num)\n",
    "    return plate_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://platerecognizer.com/wp-content/uploads/2020/07/Blur-license-plates.jpg\"\n",
    "response = requests.get(url)\n",
    "print(response)\n",
    "with open(\"dataset\\placa.jpg\", \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "    f.close()\n",
    "\n",
    "wpod_net = load_model(\"models/wpod-net.json\")\n",
    "test_image_path = \"dataset\\placa.jpg\"\n",
    "vehicle, LpImg, cor = get_plate(test_image_path, wpod_net)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.axis(False)\n",
    "ax=fig.add_subplot()\n",
    "plt.axis('off')\n",
    "plt.imshow(LpImg[0])\n",
    "extent = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "plt.savefig('detection/placas.jpg', bbox_inches=extent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "placa = cv2.imread('detection\\placas.jpg')\n",
    "letters=recognize_plate(placa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models\\model_emnist.json', 'r') as json_file:\n",
    "    model_json = json_file.read()\n",
    "    json_file.close()\n",
    "model_emnist = model_from_json(model_json)\n",
    "model_emnist.load_weights('models\\weights_emnist.h5')\n",
    "print('Modelo EMNIST cargado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.preprocessing import image\n",
    "img = image.load_img('letras\\\\5.jpg', target_size=(28,28), color_mode='grayscale')\n",
    "X = image.img_to_array(img)\n",
    "X = np.expand_dims(X, axis=0)\n",
    "preds = model_emnist.predict(X)\n",
    "print(np.argmax(preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
